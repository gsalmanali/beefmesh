<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://example.com/databases/" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Databases - BeefMesh 1.0</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Databases";
        var mkdocs_page_input_path = "databases.md";
        var mkdocs_page_url = "/databases/";
      </script>
    
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> BeefMesh 1.0
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../layout/">Layout</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../sessions/">Sessions</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../emissions/">Emissions</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utsa/">UTSA Server</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Databases</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#mariadb">MariaDB</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#mongodb">MongoDB</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#postgresql">PostgreSQL</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#cassandra">Cassandra</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#multihost-setup">Multihost Setup</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ipfs/">IPFS Network</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../iots/">IoT Network</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../overlay/">Overlay Network</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../shareddrive/">Network Shared Drive</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../blockchain/">Blockchain Network</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../utilities/">Utilities and Monitoring</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../examples/">Examples and Applications</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../debugging/">Debugging Issues</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">BeefMesh 1.0</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" aria-label="Docs"></a></li>
      <li class="breadcrumb-item active">Databases</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="databases">Databases</h1>
<p>A number of databases are setup to allow organizations to consume different types of data from events and processes occuring within the facility from which useful information can be extracted and shared. The databases can be individually spun up using docker-compose file or as part of the main setup for BeefMesh.</p>
<p><code>Note that the databases are setup individually for different organizations using internal network and does not use the global beef_suppy bridge or overlay network. This is because databases consume internal organizational data which should not be exposed to external components. Examples databases are setup for 'farmer' organization using 'farmer' network under /databases/farmer which can be extended to other organizations by reusing the same files. Specific .sql formatted tables with beef chain specific parameters are available under /databases/beefchainparameters and can be used with postgres, mariadb or mysql. The tables can be split or combined depending upon the supply chain organziation from where the specific parameters are avaialble for consumption</code>. </p>
<h3 id="mariadb">MariaDB</h3>
<p>MariaDB is an open-source relational database management system (RDBMS) and one of the most popular alternatives to MySQL.  For testing with docker as a standalone application, spin up the container by navigating into the /databases/farmer/mariadb directory.</p>
<pre><code> docker-compose up -d
</code></pre>
<p>Once up and running, there will be two containers that manage MariaDB database. Mariadb image spins up with the name 'farmermdb' and accompanying phpmyadmin contianer to manage SQL datbases runs up with the name 'phpmyadmin'. Mariadb container runs on port  "3307:3306" and phpadmin container runs on port  "8082:8080".  </p>
<p><code>For testing purposes, the environment variables are directly specified into the docker-compose file. Pass sensitive information to contianers such as credentials using 'secrets' as described in the 'Sessions' tutorial page.</code></p>
<p>The credentials 'usernames' and 'passwords' for mariadb and mysql have been set to 'farmermdb' for testing including the creation of a default database 'farmermdb'.  </p>
<p>A consistent database is attached to the container at runtime 'farmerdb_data' to keep data from being lost. Configuration for the contianers can be done using the file in 'config' folder and any number of databases and tables can be initiated using .sql formatted queries in 'init' folder. </p>
<p>Once the container is up and running, pass any sql query from files to the container, for example </p>
<pre><code>docker exec -i farmermdb  mysql -uroot  -pfarmermdb &lt; farmer.sql
</code></pre>
<p>To pass any query from bash, </p>
<pre><code>docker exec -i farmermdb  mysql -uroot  -pfarmermdb -e "show databases" 
docker exec -i farmermdb  mysql -uroot  -pfarmermdb -e "use cattle_db; show tables" 
docker exec -i farmermdb  mysql -uroot  -pfarmermdb -e "use cattle_db; show tables; select * from cattle"
</code></pre>
<p>The mariadb cli interface can also be used to do the same. For example, </p>
<pre><code>docker exec -it farmermdb mariadb --user root -pfarmermdb -e "show databases"
</code></pre>
<p>To directly access mariadb cli interface within the container, </p>
<pre><code>docker exec -it farmermdb mariadb --user root -pfarmermdb
</code></pre>
<p>Once inside the container, directly use sql queries at the prompt. In addition, it can be useful to directly access the phpmyadmin page running at 'http://localhost:8082' using 'farmermdb' for username and password. In addition, sotrage engine can be specified during the creation of database to allow utilizing the full potential for parallel or scalable application types. See more details here: https://mariadb.com/kb/en/storage-engines/</p>
<p>To bring down the Mariadb containers </p>
<pre><code>docker stop farmerpma &amp;&amp; docker stop farmermdb &amp;&amp; docker rm farmerpma &amp;&amp; docker rm farmermdb

# make backup before removing docker volume  
docker volume rm mariadb_farmerdb_data &amp;&amp; docker volume prune
</code></pre>
<h3 id="mongodb">MongoDB</h3>
<p>MongoDB is a popular open-source, NoSQL database program. It falls under the category of document-oriented databases, which means it stores data in flexible, JSON-like documents. For testing with docker as a standalone application, spin up the container by navigating into the /databases/farmer/mongodb directory.</p>
<pre><code> docker-compose up -d
</code></pre>
<p>Once up and running, there will be two containers that manage MongoDB database. MongoDB image spins up with the name 'farmermongodb' and accompanying mongo-express contianer to manage mongo datbases runs up with the name 'farmermongoexpress'. Mongodb container runs on port "27018:27017" and mongo-express container runs on port  "8089:8081". </p>
<p><code>For testing purposes, the environment variables are directly specified into the docker-compose file. Pass sensitive information to contianers such as credentials using 'secrets' as described in the 'Sessions' tutorial page.</code></p>
<p>The credentials 'usernames' and 'passwords' for mongoDB and mongo-express have been set to 'farmermdb' for testing including the creation of a default database 'farmermdb'.  </p>
<p>A consistent database is attached to the container at runtime 'farmermongo_data' to keep data from being lost. Configuration for the contianers can be done using the file in 'config' folder and any number of databases and tables can be initiated using .json formatted files in 'init' folder. Uncomment relevant lines in docker-compose script to allow using database initialization and custom configuration at container runtime. </p>
<p>Once the container is up and running, directly access the continer,  </p>
<pre><code>docker exec -it farmermongodb bash
</code></pre>
<p>Once inside the container, access mongo cli interace,</p>
<pre><code>mongo mongodb://localhost:27017 -u farmermdb -p farmermdb
</code></pre>
<p>More details on Mongodb shell commands can be found at: https://www.mongodb.com/docs/mongodb-shell/run-commands/</p>
<p>You can also directly access the shell in one go, </p>
<pre><code>docker exec -it farmermongodb mongo mongodb://localhost:27017 -u farmermdb -p farmermdb
</code></pre>
<p>Or pass any command to mongo shell from outside the container using bash. For example, create a new user credential and a database named 'farmer', </p>
<pre><code>docker exec -it farmermongodb mongo  mongodb://localhost:27017 -u farmermdb -p farmermdb --eval "db.createUser({user: 'farmer', pwd: 'farmer', roles: [{role: 'readWrite', db: 'farmer'}]})"
</code></pre>
<p>With the flexiblity of mongodb database to store massive collections of data in json format, it is an ideal database for consuming beef supply chain data,  storing documents and sensor data. To store a collection of data in .json format, lets first copy the data file (cattle_data.json) into the container in /tmp folder. </p>
<pre><code>docker cp databases/farmer/mongodb/cattle_data.json farmermongodb:/tmp/cattle_data.json
</code></pre>
<p>Next, login into the container and use 'mongoimport' tool to put the example file in a database,</p>
<pre><code>docker exec -it farmermongodb bash
# Inside the container run,
mongoimport --host localhost --port 27017 --username farmermdb --password farmermdb --authenticationDatabase admin --db farmermdb --collection farmermdb --file tmp/cattle_data.json --jsonArray
</code></pre>
<p>You can also run the command directly from outside the container using bash once you have copied the file into the container, </p>
<pre><code>docker exec -it farmermongodb mongoimport --host localhost --port 27017 --username farmermdb --password farmermdb --authenticationDatabase admin --db farmermdb --collection farmermdb --file tmp/cattle_data.json --jsonArray
</code></pre>
<p>To retireve a collection of data from a database, </p>
<pre><code>docker exec -it farmermongodb mongoexport --host localhost --port 27017 --username farmermdb --password farmermdb --authenticationDatabase admin --db farmermdb --collection farmermdb --out exported_data.json
</code></pre>
<p>This retrieves  the data collection and saves into the output file exported_data.json. You can copy the file to host machine from the container, </p>
<pre><code>docker cp farmermongodb:exported_data.json exported_data.json
</code></pre>
<p>Or you can directly retreive data from the database collection and store it in the host machine using bash,</p>
<pre><code>docker exec -it farmermongodb mongoexport --host localhost --port 27017 --username farmermdb --password farmermdb --authenticationDatabase admin --db farmermdb --collection farmermdb &gt; exported_data_direct.json
</code></pre>
<p>The data will be stored in a file 'exported_data_direct.json' in the host machine.  </p>
<p>In addition, it can be useful to diretly access the mongo-express page running at 'http://127.0.0.1:8089' or 'localhost:8089' using 'farmermdb' for username and password. Mongoexpress allows a graphical interface to manage databases stored in mongodb. </p>
<p>To bring down the MongoDB containers </p>
<pre><code>docker stop farmermongoexpress &amp;&amp; docker stop farmermongodb &amp;&amp; docker rm farmermongoexpress &amp;&amp; docker rm farmermongodb

# make backup before removing docker volume  
docker volume rm mongodb_farmermongo_data &amp;&amp; docker volume prune
</code></pre>
<h3 id="postgresql">PostgreSQL</h3>
<p>PostgreSQL, which is a powerful open-source relational database management system (RDBMS). For testing with docker as a standalone application, spin up the container by navigating into the /databases/farmer/postgresql directory.</p>
<pre><code> docker-compose up -d
</code></pre>
<p>Once up and running, there will be two containers that manage MongoDB database. PostgreSQL image spins up with the name 'farmerpostgres' and accompanying pgadmin contianer to manage potgres datbases runs up with the name 'padmin_farmer'. Postgres container runs on port "5431:5432" and pgadmin container runs on port  "8887:80". </p>
<p><code>For testing purposes, the environment variables are directly specified into the docker-compose file. Pass sensitive information to contianers such as credentials using 'secrets' as described in the 'Sessions' tutorial page.</code></p>
<p>The credentials 'usernames' and 'passwords' for postgres and pgadmin have been set to 'farmermdb' for testing including the creation of a default database 'farmermdb'.  </p>
<p>A consistent volume is attached to the container at runtime 'farmerpostgres' including a drive 'farmerpostgres_data' to keep data from being lost. Configuration for the contianers can be done using the file in 'config' folder and any number of databases and tables can be initiated using .sql formatted files in 'init' folder. Uncomment relevant lines in docker-compose script to allow using database initialization and custom configuration at container runtime. </p>
<p>Once the container is up and running, directly access the continer,  </p>
<pre><code>docker exec -it farmerpostgres sh
</code></pre>
<p>Once inside the container, access psql cli interace and enter password 'farmermdb',</p>
<pre><code>psql -h localhost -p 5432 -U farmermdb -W
</code></pre>
<p>More details on psql shell commands can be found at: https://www.postgresql.org/docs/current/tutorial.html</p>
<p>To retrieve (import) an already existing database 'farmermdb' created at runtime, into the host machine using 'pg_dump' from bash terminal, </p>
<pre><code>docker exec -i farmerpostgres  /bin/bash -c "PGPASSWORD=farmermdb pg_dump --username farmermdb farmermdb" &gt; retrieved_data.sql
</code></pre>
<p>To upload or export data with creation of a new database, first copy .sql file into the container under /tmp folder, </p>
<pre><code>docker cp farmerpostgres_data/cattle.sql farmerpostgres:/tmp/cattle.sql
</code></pre>
<p>Next sh into the container and use 'psql' cli interface to upload data,</p>
<pre><code>docker exec -it farmerpostgres sh
# Type inside the container terminal, 
psql -U farmermdb farmermdb -f /tmp/cattle.sql
</code></pre>
<p>You can also upload data into the database without going inside the container and just using the host terminal and using the file in /tmp folder, </p>
<pre><code>docker exec -i farmerpostgres psql -U farmermdb farmermdb -f /tmp/cattle.sql
</code></pre>
<p>Now to retrieve the same uploaded data in the database 'cattle_db', </p>
<pre><code>docker exec -i farmerpostgres  /bin/bash -c "PGPASSWORD=farmermdb pg_dump --username farmermdb cattle_db" &gt; retrieved_cattle_db.sql
</code></pre>
<p>In addition, it can be useful to diretly access the pgadmin page running at 'http://127.0.0.1:8887' or 'http://localhost:8887' using 'farmermdb' for username and password. Pgadmin allows a graphical interface to manage databases stored in postgres. Go to 'servers' tab on the left side, create new server connection using localhost as the 'host', port 5431, database 'farmermdb', username and password 'farmermdb'.</p>
<p>To bring down the Postgres containers </p>
<pre><code>docker stop farmerpostgres &amp;&amp; docker stop padmin_farmer &amp;&amp; docker rm farmerpostgres &amp;&amp; docker rm padmin_farmer

# make backup before removing docker volume  
docker volume rm postgresdb_farmerpostgres &amp;&amp; docker volume rm postgresdb_padmin_farmer &amp;&amp; docker volume prune
</code></pre>
<h3 id="cassandra">Cassandra</h3>
<p>Cassandra is NoSQL database particularly well-suited for use cases where fast reads and writes are essential, and where data needs to be distributed across multiple locations. For testing with docker as a standalone application, spin up the container by navigating into the /databases/farmer/cassandradb directory.</p>
<pre><code> docker-compose up -d
</code></pre>
<p>Once up and running, there will be a container running Cassandra database. Cassandra image spins up with the name 'farmercassdb'. The container runs on port "9034:9042" in addition to ports 7000, 7001, 7199 and 9160 exposed for various functions associated with cassandra. </p>
<p><code>For testing purposes, the environment variables are directly specified into the docker-compose file. Pass sensitive information to contianers such as credentials using 'secrets' as described in the 'Sessions' tutorial page.</code></p>
<p>The credentials 'usernames' and 'passwords' have been set to 'cassandra' for testing.</p>
<p>A consistent volume is attached to the container at runtime 'farmercassdb_data' to keep data from being lost. Configuration for the contianers can be done using .yaml files present in the /databases/cassandra/etc folder and including it in the docker-compose file at runtime. A sample docker-compose-cluster.yaml file is also provided if a cluster of cassandra databases is requuired with different configurations for each database inherited from files in /etc folder. </p>
<p>Once the container is up and running, check the status of the node (or cluster)</p>
<pre><code>  docker exec -it farmercassdb  nodetool status
</code></pre>
<p>Directly access the cqlsh cli interace in container,  </p>
<pre><code>docker exec -it farmercassdb sh

cqlsh

# Alernate one liner
docker exec -it farmercassdb cqlsh
</code></pre>
<p>More details on cqlsh shell commands can be found at: https://cassandra.apache.org/doc/stable/cassandra/tools/cqlsh.html</p>
<p>Once, inside the container, create a keyspace (a namespace used for replicating data on multiple nodes) and use it as a test database, </p>
<pre><code>CREATE KEYSPACE my_cattle WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 1};

use my_cattle
</code></pre>
<p>Once the keyspace has been selected for use, create a sample table,</p>
<pre><code>CREATE TABLE IF NOT EXISTS cattle_data (
id UUID PRIMARY KEY,
name TEXT,
breed TEXT,
age INT,
weight FLOAT
);
</code></pre>
<p>Now, insert sample data into the table, </p>
<pre><code>INSERT INTO cattle_data (id, name, breed, age, weight) 
VALUES (uuid(), 'Bessie', 'Holstein', 4, 1200.5);

INSERT INTO cattle_data (id, name, breed, age, weight) 
VALUES (uuid(), 'Daisy', 'Angus', 3, 1100.2);

INSERT INTO cattle_data (id, name, breed, age, weight) 
VALUES (uuid(), 'Spot', 'Hereford', 5, 1300.8);
</code></pre>
<p>Retrieve, data from table, </p>
<pre><code>SELECT * FROM cattle_data;
</code></pre>
<p>You can also directly pass commands from host terminal without logging into the container,</p>
<pre><code>docker exec -it farmercassdb cqlsh -e "CREATE KEYSPACE my_cattle WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 1};"


docker exec -it farmercassdb cqlsh -e "use my_cattle; CREATE TABLE IF NOT EXISTS cattle_data (id UUID PRIMARY KEY, name TEXT, breed TEXT, age INT, weight FLOAT); INSERT INTO cattle_data (id, name, breed, age, weight) VALUES (uuid(), 'Bessie', 'Holstein', 4, 1200.5); SELECT * FROM cattle_data;"

# Or dump data directly to a file (data_out.txt) in host machine
docker exec -it farmercassdb cqlsh -e "use my_cattle; CREATE TABLE IF NOT EXISTS cattle_data (id UUID PRIMARY KEY, name TEXT, breed TEXT, age INT, weight FLOAT); INSERT INTO cattle_data (id, name, breed, age, weight) VALUES (uuid(), 'Bessie', 'Holstein', 4, 1200.5); SELECT * FROM cattle_data;" &gt; data_out.txt
</code></pre>
<p>It is also possible to create tables and upload data from .cql files. </p>
<p>Copy sample .cql file in the cassandra folder into the container,</p>
<pre><code>docker cp cattle.cql farmercassdb:/cattle.cql
</code></pre>
<p>Access the docker container cqlsh shell and source the file, </p>
<pre><code>docker exec -it farmercassdb cqlsh


source '/cattle.cql';
</code></pre>
<p>You can also directly pass the commands from host bash terminal after copying the file to the container,</p>
<pre><code>   docker exec -it farmercassdb cqlsh -e "source '/cattle.cql';"
</code></pre>
<p>To use cassandra cluster, use the docker-compose-cluster.yaml file after configurig required changes. This may generate a lot of commit log files locally in commitlog/ folder, hence make sure there is tons space before running cluster. </p>
<p>In addition, it can be useful to directly access the cassandradb-web page running at 'http://127.0.0.1:3003' or 'http://localhost:3003' to manage existing clusters or to create new cassandradb clusters. The cassandradb-web username and password are set to "cassandra". </p>
<p>To bring down the cassandra containers and remove commit log files</p>
<pre><code>docker stop farmercassdb &amp;&amp; docker rm farmercassdb &amp;&amp; docker stop cassandra-web &amp;&amp; docker rm cassandra-web

# make backup before removing docker volume  
docker volume rm cassandradb_farmercassdb_data &amp;&amp; docker volume prune

# remove commitlog files
rm commitlog/cassandra1/* &amp;&amp; rm commitlog/cassandra2/*  &amp;&amp; rm commitlog/cassandra3/* 
# remove cluster data files after backing up 
rm data/cassandra1/* &amp;&amp; rm data/cassandra2/*  &amp;&amp; rm data/cassandra3/*
</code></pre>
<h3 id="multihost-setup">Multihost Setup</h3>
<p>The databases are supposed to be run within each organization and should not be accessible from outside, hence the docker shell can be directly accessed from an administrator to upload or retrieve data. The containers connect to 'farmer' network as a bridge which can be changed to other networks or connections depending upon the applciation scenario using the scripts in /utilities folder. To allow other users with limited rights to view or upload data, create new user accounts directly for the databases and allow users to access the web management portal for the databases by updating and sourcing environment varibles for the deployed url of web tools.</p>
<pre><code>  # from BeefMesh main directory 
  source environment/service_ip_addresses.sh

  # access phpmyadmin page for mariadb 
  http://$mariadb_server_address:8082

  # access mongo-express page for mongodb 
  http://$mongodb_server_address:8089

  # access pgadmin page for postres 
  http://$postgres_server_address:8087

  # access cassandra-web page for mariadb 
  http://$cassandra_server_address:3003
</code></pre>
<p>Other options could include resuing the flask-based applications for emissions and sessions sub-module to render specific CRUD api for different stored schemas </p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../utsa/" class="btn btn-neutral float-left" title="UTSA Server"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../ipfs/" class="btn btn-neutral float-right" title="IPFS Network">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../utsa/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../ipfs/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "..";</script>
    <script src="../js/theme_extra.js"></script>
    <script src="../js/theme.js"></script>
      <script src="../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
